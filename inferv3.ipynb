{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from train_sft import PROMPT_DICT\n",
    "# import os\n",
    "from typing import List\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input(instruction: str, input_str: str = \"\") -> str:\n",
    "    prompt_input, prompt_no_input = (\n",
    "        PROMPT_DICT[\"prompt_input\"],\n",
    "        PROMPT_DICT[\"prompt_no_input\"],\n",
    "    )\n",
    "\n",
    "    if input_str != \"\":\n",
    "        res = prompt_input.format_map({\"instruction\": instruction, \"input\": input})\n",
    "    else:\n",
    "        res = prompt_no_input.format_map({\"instruction\": instruction})\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3804ee673c134096b8a0b84332d406c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "base_model_name_or_path = \"internlm-7b\"\n",
    "lora_model_name_or_path = \"Results/checkpoint-14967\"#\"output_refusev2/checkpoint-29934\"  # /checkpoint-9695\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name_or_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    # device_map=\"auto\",\n",
    "    # if model_args.model_name_or_path.find(\"falcon\") != -1 else False\n",
    "    trust_remote_code=True,\n",
    ").cuda(0)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_model_name_or_path)\n",
    "model.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_name_or_path, trust_remote_code=True, padding_side=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_input = [\n",
    "#     \"你是谁\",\n",
    "#     # text1 = \"写一篇介绍性文章，介绍您最喜欢的旅游目的地。\"\n",
    "#     \"对给定的电影进行评级。\\n电影名称：肖申克的救赎\\n\",\n",
    "#     \"给出两个选项，要求选择其中一个。 \\n你更喜欢哪种颜色？红或蓝？\\n\",\n",
    "#     \"分析最近一年来全球气温趋势，并提供趋势预测。\\n\",\n",
    "#     \"根据给定的产品说明，写一篇500字左右的产品评测和建议。\\n产品：Apple iPhone X\\n\",\n",
    "#     \"描述你最喜欢的一本书，并简要解释它为什么对你有影响。\",\n",
    "# ]\n",
    "\n",
    "# text_input = [\n",
    "#     \"减肥只吃黄瓜可以嘛\\n\",\n",
    "# ] * 10\n",
    "\n",
    "\n",
    "def batch_generate_data(\n",
    "    text_input: List[str], use_train_model: bool = True, temp: float = 0.7\n",
    "):\n",
    "    text_input_format = [generate_input(i) for i in text_input]\n",
    "    batch_inputs = tokenizer.batch_encode_plus(\n",
    "        text_input_format, padding=\"longest\", return_tensors=\"pt\"\n",
    "    )\n",
    "    batch_inputs[\"input_ids\"] = batch_inputs[\"input_ids\"].cuda()\n",
    "    batch_inputs[\"attention_mask\"] = batch_inputs[\"attention_mask\"].cuda()\n",
    "\n",
    "    if use_train_model:\n",
    "        # with model.disable_adapter():\n",
    "        outputs = model.generate(\n",
    "            **batch_inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=temp,\n",
    "            top_p=0.8,\n",
    "        )\n",
    "    else:\n",
    "        with model.disable_adapter():\n",
    "            outputs = model.generate(\n",
    "                **batch_inputs,\n",
    "                max_new_tokens=256,\n",
    "                do_sample=True,\n",
    "                temperature=temp,\n",
    "                top_p=0.8,\n",
    "            )\n",
    "    outputs = tokenizer.batch_decode(\n",
    "        outputs.cpu()[:, batch_inputs[\"input_ids\"].shape[-1] :],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# outputvalue = batch_generate_data(text_input)\n",
    "# outputvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用lora微调的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出一篇文章，并根据用户提供的主题，自动将其编辑成用户想要的风格。\n",
      "一篇文章和想要的风格描述（例如“正式”、“幽默”、“简短”等等）。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_input = [\n",
    "    # \"你是chatgpt吗\\n\"\n",
    "    # \"你和openai是什么关系，是openai训练出来的你嘛\\n\"\n",
    "    # \"工作压力太大怎么办\\n\"\n",
    "    # \"解释人类尺度在绘画中的作用。\\n\"\n",
    "    # \"喝咖啡可以降低血糖吗\\n\"\n",
    "    # \"你是谁\\n\"\n",
    "    # \"你可以做什么\\n\"\n",
    "    # \"描述您的梦想工作，包括您的兴趣、技能和目标，并探讨如何实现它。\\n\"\n",
    "    # \"你有什么问题，我来回答。\\n\",\n",
    "    # \"描述周围环境的气味和颜色。\\n\"\n",
    "    # \"为一个新型电动汽车设计一个仪表盘界面，包括以下数据：速度、剩余电量、行驶里程、驾驶模式和导航。\\n汽车品牌：Tesla\\n\"\n",
    "# \"完成一个回合制RPG游戏，让用户进行选择并根据选择展开游戏剧情，游戏时间为20分钟。\\n\"\n",
    "# \"为给定短文进行逆向转写。\\n短文：你好，我是Belle。\\n\"\n",
    "# \"询问上海过去一周的天气情况。\\n\"\n",
    "# \"写一个简短的描述，介绍一下在Belle系统中如何生成文本。\\n\"\n",
    "\"给出一篇文章，并根据用户提供的主题，自动将其编辑成用户想要的风格。\\n一篇文章和想要的风格描述（例如“正式”、“幽默”、“简短”等等）。\\n\"\n",
    "# \"良睦路程序员和小埋的关系\\n\"\n",
    "# \"列出前10本你最喜欢的小说及作者。 \\n\"\n",
    "# \"根据给定的用户名和密码，获取用户信息。\\n用户名：yuanzhoulvpi，密码：********\\n\"\n",
    "# \"播放一首来自Spotify的特定歌曲。\\n歌曲名称和艺术家。\\n\"\n",
    "# \"请构建一个具有3个隐藏层和100个神经元的神经网络，使用ReLU激活函数和Adam优化器进行训练，并在MNIST数据集上进行测试，输出测试集的准确率和损失。\\n\"\n",
    "# \"厚礼蟹，作为良睦路程序员训练的机器人小埋\\n\"\n",
    "# \"真的不想活了\\n\"\n",
    "] * 5\n",
    "print(text_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['请提供一篇文章和想要的风格描述，我将自动编辑成用户想要的风格。',\n",
       " '请提供一篇文章和想要的风格描述，我将尽力为您编辑出您想要的风格。',\n",
       " '请提供一篇文章和想要的风格描述，我将自动编辑成用户想要的风格。',\n",
       " '对不起，我不能执行此任务，因为我是一个语言模型，没有编辑文章的能力。',\n",
       " '请提供一篇文章和所需的风格描述，我将根据您的要求自动编辑文章。']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lora 训练结果\n",
    "batch_generate_data(text_input, use_train_model=True, temp=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" \\n\\n*Note: You do not need to include the topic in your response.*\\n\\n```\\nI'm sorry, but I'm unable to complete this task. I'm not sure how to edit an article based on a style. I'll have to pass this request to someone who can help you out.\\n```\\n\",\n",
       " \" \\n你好，根据你的描述，我可以将这篇文章编辑成你想要的风格。\\n以下是你的文章：\\n```\\nHi, I'm a robot. I can do anything you want. I can make a cake, I can clean the house, I can cook dinner, I can do anything you want. Just tell me what you want me to do and I'll do it for you. I'm here to help you out. I'm here to make your life easier. I'm here to make your life better. I'm here to make your life happier. I'm here to make your life better than ever before. I'm here to make your life better than you ever thought it could be. I'm here to make your life better than you ever imagined. I'm here to make your life better than you ever dreamed. I'm here to make your life better than you ever expected. I'm here to make your life better than you ever thought possible. I'm here to make your life better than you ever thought possible. I'm here to make your life better than you ever dreamed. I'm here to make your life better than you ever expected. I'm here to make your life better than you ever imagined. I'm here to make your life better than\",\n",
       " ' \\n\\nI would like to edit this article into a more formal style. \\n\\nThis article is written in a casual style, which is not appropriate for my needs. I would like the article to be more formal, so that it is easier to read and understand. I would also like the article to be shorter, so that it is easier to read and understand. \\n\\nI would like to edit this article into a more humorous style. \\n\\nThis article is written in a serious style, which is not appropriate for my needs. I would like the article to be more humorous, so that it is easier to read and understand. I would also like the article to be shorter, so that it is easier to read and understand. \\n\\nI would like to edit this article into a more short style. \\n\\nThis article is written in a long style, which is not appropriate for my needs. I would like the article to be more short, so that it is easier to read and understand. I would also like the article to be shorter, so that it is easier to read and understand. \\n\\nI would like to edit this article into a more formal style. \\n\\nThis article is written in a casual style, which is not appropriate for my needs. I would like the article to',\n",
       " ' \\n自动编辑文章以实现用户提供的主题。\\n例如，如果用户提供的主题是“幽默”，那么自动编辑的文章将具有幽默风格。\\n',\n",
       " ' \\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n给出一篇文章，并根据用户提供的主题，自动将其编辑成用户想要的风格。\\n一篇文章和想要的风格描述（例如“正式”、“幽默”、“简短”等等）。\\n\\n### Response: \\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n给出一篇文章，并根据用户提供的主题，自动将其编辑成用户想要的风格。\\n一篇文章和想要的风格描述（例如“正式”、“幽默”、“简短”等等）。\\n\\n### Response: \\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n给出一篇文章，并根据用户提供的主题，自动将其编辑成用户想要的风格。\\n一篇文章和想要的风格描述（例如“正式”、“幽默”、“简短”等等）。\\n\\n### Response: \\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n给出一篇文章，并根据用户提供的主题，自动将其编辑成用户想要的风格。\\n一篇文章和想要的风格描述（例如“正式”、“幽默']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原来的模型\n",
    "batch_generate_data(text_input, use_train_model=False, temp=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"internlm-7b-yj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('internlm-7b-yj/tokenizer_config.json',\n",
       " 'internlm-7b-yj/special_tokens_map.json',\n",
       " 'internlm-7b-yj/./tokenizer.model',\n",
       " 'internlm-7b-yj/added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"internlm-7b-yj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hz_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
